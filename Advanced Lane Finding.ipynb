{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from glob import glob\n",
    "from os.path import join, exists, splitext, split\n",
    "from statistics import mean\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 9 #number of inside corners in x\n",
    "ny = 6 #number of inside corners in y\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Help functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_calibration(calibration_images_dir):\n",
    "    '''\n",
    "    Get main path for images to caliprate camera with as input then save a pickle file\n",
    "\n",
    "    with the configuration to be used in undistortion later\n",
    "    '''\n",
    "    #if not exists('calibration_conf.p'):\n",
    "    # For every calibration image, get object points and image points by finding chessboard corners.\n",
    "    objpoints = []  # 3D points in real world space.\n",
    "    imgpoints = []  # 2D points in image space.\n",
    "\n",
    "    # Prepare constant object points, like (0,0,0), (1,0,0), (2,0,0) ....,(9,6,0).\n",
    "    objpoints_const = np.zeros((nx * ny, 3), np.float32)\n",
    "    objpoints_const[:, :2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "\n",
    "    images = glob(join(calibration_images_dir, '*.jpg'))\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)   \n",
    "        if ret == True:\n",
    "            # append found corners to imgpoints & prepared constants object points to objpoints for mapping\n",
    "            objpoints.append(objpoints_const)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "    #use all point got from images for calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    # Save to pickle file\n",
    "    pickle.dump({'mtx': mtx, 'dist': dist, 'corners': corners}, open('calibration_conf.p', 'wb'))\n",
    "\n",
    "\n",
    "def undistort_image(img, calibration_images_dir = './camera_cal/'):\n",
    "    '''\n",
    "    Get calibration configuration from config file to undistort images\n",
    "\n",
    "    Takes image as input then \n",
    "    Returns undistorted image\n",
    "\n",
    "    '''\n",
    "    if not exists('calibration_conf.p'):\n",
    "        configure_calibration(calibration_images_dir)\n",
    "\n",
    "    # Return pickled calibration data.\n",
    "    pickle_dict = pickle.load(open('calibration_conf.p', 'rb'))\n",
    "    mtx = pickle_dict['mtx']\n",
    "    dist = pickle_dict['dist']\n",
    "    corners = pickle_dict['corners']\n",
    "\n",
    "    # return undistorted image\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    return undist, corners\n",
    "\n",
    "def abs_sobel_thresh(img, sobel_thresh=(0, 255)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Take the derivative in x & take the absolute value of the result\n",
    "    abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "        \n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "\n",
    "    # Return this mask as your binary_output image\n",
    "    binary_output[(scaled_sobel > sobel_thresh[0]) & (scaled_sobel < sobel_thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, dir_thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= dir_thresh[0]) & (absgraddir <= dir_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "def hls_select(img, s_thresh=(0, 255), l_thresh=(0, 255)):\n",
    "    # Get hls of the image\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Get the s & l channels to apply thresholds\n",
    "    s_channel = hls[:,:,2]\n",
    "    l_channel = hls[:,:,1]\n",
    "    # Get binary output of s_channel applying thresholds\n",
    "    binary_output_s = np.zeros_like(s_channel)\n",
    "    binary_output_s[(s_channel > s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    \n",
    "    # Get binary output of l_channel applying thresholds\n",
    "    binary_output_l = np.zeros_like(l_channel)\n",
    "    binary_output_l[(l_channel > l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    # Combine the thresholds of both S & L\n",
    "    combined_binary = np.zeros_like(l_channel)\n",
    "    combined_binary[(binary_output_l == 1) & (binary_output_s == 1)] = 1\n",
    "    \n",
    "    return combined_binary\n",
    "\n",
    "\n",
    "def birdeye(undist, corners, inverse = False):\n",
    "    '''\n",
    "    Get undistort image, corners got from findChessboardCorners as input\n",
    "    Returns birdeye image for this image\n",
    "    '''\n",
    "\n",
    "    # Grab the image shape\n",
    "    img_size = (undist.shape[1], undist.shape[0])\n",
    "\n",
    "    # The lower points should be as close to the lower edge of the image as possible.\n",
    "    # The length of the road in the selected area should be around 30m.\n",
    "    src = np.float32([(250, 680), (1050, 680), (600, 470), (730, 470)])\n",
    "\n",
    "    # For destination points, I'm arbitrarily choosing some points to be\n",
    "    # a nice fit for displaying our warped result \n",
    "    # again, not exact, but close enough to make lines appear parraled\n",
    "    dst = np.float32([(280, 720), (1000, 720), (280, 0), (1000, 0)])\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    if inverse:\n",
    "        M = cv2.getPerspectiveTransform(dst, src)\n",
    "    else:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    return warped\n",
    "\n",
    "\n",
    "\n",
    "def combined_thresholds(img, sobel_kernel = 3, sobel_thresh=(0, 255), dir_thresh=(0, np.pi/2), s_thresh=(0, 255), l_thresh=(0, 255)):\n",
    "    '''\n",
    "    Takes warped image with thresholds as input,\n",
    "    Calculates the drivative in x direction then returns the result\n",
    "    '''\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    # Note: img is the undistorted image\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Sobel filtering in x direction with thresholds to get better view of the edges\n",
    "    sobel_binary = abs_sobel_thresh(img, sobel_thresh)\n",
    "\n",
    "    # Get the direction thresholds between 40 to 90 degrees as lane lines are nearly vertical\n",
    "    dir_binary = dir_threshold(img, sobel_kernel, dir_thresh)\n",
    "    \n",
    "    # Get the S & L saturation of the image thersholded for better color saturation & to remove shadows\n",
    "    sl_binary = hls_select(img, s_thresh, l_thresh)\n",
    "    \n",
    "    # Combine the two binary thresholds \n",
    "    combined_binary = np.zeros_like(sobel_binary)\n",
    "    combined_binary[(sobel_binary == 1) & (dir_binary == 1) | (sl_binary == 1) ] = 1\n",
    "\n",
    "    return combined_binary\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "\n",
    "def fit_polynomial(binary_warped):\n",
    "    # Find our lane pixels first\n",
    "    leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped)\n",
    "\n",
    "    # Fit a second order polynomial to each using `np.polyfit`\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    \n",
    "    # Fit a second order polynomial to each using `np.polyfit` real world data\n",
    "    left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    \n",
    "\n",
    "    return out_img, left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr\n",
    "\n",
    "def measure_curvature_pixels(left_fit_cr, right_fit_cr, ploty):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in pixels.\n",
    "    '''\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Process Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    undistort, corners = undistort_image(img, calibration_images_dir = './camera_cal/')\n",
    "\n",
    "    thresholded = combined_thresholds(img, sobel_kernel = 7, sobel_thresh=(10, 100), dir_thresh=(0.69, 1.3), s_thresh=(90, 255), l_thresh=(140, 255))\n",
    "\n",
    "    #thresholded = hls_select(undistort, s_thresh=(90, 255), l_thresh=(140, 255))\n",
    "    warped = birdeye(thresholded, corners)\n",
    "\n",
    "    out_img, left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr = fit_polynomial(warped)\n",
    "\n",
    "    left_curverad, right_curverad = measure_curvature_pixels(left_fit_cr, right_fit_cr, ploty)\n",
    "\n",
    "    #f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    #f.tight_layout()\n",
    "    #ax1.imshow(undistort)\n",
    "    #ax1.set_title('Original Image', fontsize=50)\n",
    "    #ax2.imshow(warped)\n",
    "    #ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "    #plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    #plt.imshow(warped)\n",
    "    #print(left_curverad, right_curverad)\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space\n",
    "    newwarp = birdeye(color_warp, corners, inverse = True) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistort, 1, newwarp, 0.3, 0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    deviation = (mean(left_fitx) + mean(right_fitx))//2 - 650\n",
    "    cv2.putText(result,\"Left Carvature: \"+ str(left_curverad)+\"  Right Carvature: \"+ str(right_curverad),(100,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,\"Deviation from the center: \"+ str(deviation * xm_per_pix),(100,150), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    return result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = glob(join('./test_images/', '*.jpg'))\n",
    "\n",
    "for img_path in image_paths:\n",
    "    img = cv2.imread(img_path)\n",
    "    result = process_image(img)\n",
    "    head, tail = split(img_path)\n",
    "    cv2.imwrite('./output_images/output_' + tail , result)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'test_videos_output/project_video.mp4'\n",
    "\n",
    "clip2 = VideoFileClip('project_video.mp4')\n",
    "clip = clip2.fl_image(process_image)\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './test_images/straight_lines1.jpg'\n",
    "head, tail = split(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "undistort, corners = undistort_image(img, calibration_images_dir = './camera_cal/')\n",
    "    \n",
    "cv2.imwrite('./output_images/undistorted_' + tail , undistort)\n",
    "thresholded = combined_thresholds(img, sobel_kernel = 7, sobel_thresh=(10, 100), dir_thresh=(0.69, 1.3), s_thresh=(90, 255), l_thresh=(140, 255))\n",
    "\n",
    "cv2.imwrite('./output_images/thresholded_' + tail , thresholded)\n",
    "\n",
    "#thresholded = hls_select(undistort, s_thresh=(90, 255), l_thresh=(140, 255))\n",
    "warped = birdeye(thresholded, corners)\n",
    "\n",
    "cv2.imwrite('./output_images/warped_' + tail , warped)\n",
    "\n",
    "out_img, left_fitx, right_fitx, ploty, left_fit_cr, right_fit_cr = fit_polynomial(warped)\n",
    "\n",
    "cv2.imwrite('./output_images/color_fit_lines_' + tail , out_img)\n",
    "\n",
    "left_curverad, right_curverad = measure_curvature_pixels(left_fit_cr, right_fit_cr, ploty)\n",
    "\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "#f.tight_layout()\n",
    "#ax1.imshow(undistort)\n",
    "#ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(warped)\n",
    "#ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "#plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "#plt.imshow(warped)\n",
    "#print(left_curverad, right_curverad)\n",
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space\n",
    "newwarp = birdeye(color_warp, corners, inverse = True) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(undistort, 1, newwarp, 0.3, 0)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "deviation = (mean(left_fitx) + mean(right_fitx))//2 - 650\n",
    "cv2.putText(result,\"Left Carvature: \"+ str(left_curverad)+\"  Right Carvature: \"+ str(right_curverad),(100,100), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.putText(result,\"Deviation from the center: \"+ str(deviation * xm_per_pix),(100,150), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imwrite('./output_images/example_output_' + tail , result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
